{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Pre-Processing Data Steps for Machine Learning\n",
    "#### 1. Get the Data Set (.csv)\n",
    "#### 2. Import the Libraries\n",
    "#### 3. Import the Data Set\n",
    "#### 4. Handle Missing Data\n",
    "#### 5. Handle Categorical Data\n",
    "#### 6. Split the Data Set into the Training and Testing Set\n",
    "#### 7. Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must load the data set before pre-processing\n",
    "* We will be using the customers.csv file in \"data/customers.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data/csv file\n",
    "customers_df = pd.read_csv(\"data/customers.csv\")\n",
    "\n",
    "# output the dataframe\n",
    "customers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Country</th>        <th class=\"col_heading level0 col1\" >Age</th>        <th class=\"col_heading level0 col2\" >Salary</th>        <th class=\"col_heading level0 col3\" >Purchased</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row0_col0\" class=\"data row0 col0\" >France</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row0_col1\" class=\"data row0 col1\" >44</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row0_col2\" class=\"data row0 col2\" >72000</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row0_col3\" class=\"data row0 col3\" >No</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row1_col0\" class=\"data row1 col0\" >Spain</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row1_col1\" class=\"data row1 col1\" >27</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row1_col2\" class=\"data row1 col2\" >48000</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row1_col3\" class=\"data row1 col3\" >Yes</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row2_col0\" class=\"data row2 col0\" >Germany</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row2_col1\" class=\"data row2 col1\" >30</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row2_col2\" class=\"data row2 col2\" >54000</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row2_col3\" class=\"data row2 col3\" >No</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row3_col0\" class=\"data row3 col0\" >Spain</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row3_col1\" class=\"data row3 col1\" >38</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row3_col2\" class=\"data row3 col2\" >61000</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row3_col3\" class=\"data row3 col3\" >No</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row4_col0\" class=\"data row4 col0\" >Germany</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row4_col1\" class=\"data row4 col1\" >40</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row4_col2\" class=\"data row4 col2\" >nan</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row4_col3\" class=\"data row4 col3\" >Yes</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row5_col0\" class=\"data row5 col0\" >France</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row5_col1\" class=\"data row5 col1\" >35</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row5_col2\" class=\"data row5 col2\" >58000</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row5_col3\" class=\"data row5 col3\" >Yes</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row6_col0\" class=\"data row6 col0\" >Spain</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row6_col1\" class=\"data row6 col1\" >nan</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row6_col2\" class=\"data row6 col2\" >52000</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row6_col3\" class=\"data row6 col3\" >No</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row7_col0\" class=\"data row7 col0\" >France</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row7_col1\" class=\"data row7 col1\" >48</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row7_col2\" class=\"data row7 col2\" >79000</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row7_col3\" class=\"data row7 col3\" >Yes</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row8_col0\" class=\"data row8 col0\" >Germany</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row8_col1\" class=\"data row8 col1\" >50</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row8_col2\" class=\"data row8 col2\" >83000</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row8_col3\" class=\"data row8 col3\" >No</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row9_col0\" class=\"data row9 col0\" >France</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row9_col1\" class=\"data row9 col1\" >37</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row9_col2\" class=\"data row9 col2\" >67000</td>\n",
       "                        <td id=\"T_cfc0b230_61b6_11ea_a000_f82819e8e930row9_col3\" class=\"data row9 col3\" >Yes</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24399beff08>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a dictionary to format specific columns\n",
    "customers_df.style.format({\"Salary\":\"{:.0f}\"})\n",
    "\n",
    "# or set float format for all dataframes\n",
    "# pd.set_option('display.float_format','{:.1f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is 'x'?\n",
    "The x (independent variable) is a 2D Array of the Country, Age, and Salary columns.\n",
    "* Each column is an independent variable\n",
    "* Each row is a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, nan],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', nan, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a 2D array excluding the last column (independent variable vector)\n",
    "# '[:,' - all rows\n",
    "# ',:-1]' - all columns except the last one\n",
    "x = customers_df.iloc[:, :-1].values\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is 'y'?\n",
    "The y (dependent variable) is an Array of the Purchased column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a 2D array of the last column (dependent variable vector)\n",
    "y = customers_df.iloc[:, 3].values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So What's the Machine Learning (ML) Problem?\n",
    "The Purchased column is dependent on the Country, Age, and Salary.\n",
    "\n",
    "Therefore, can we can make predictions on whether a customer will purchase an item based on their country, age, and salary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Data\n",
    "The customers data set contains some \"NaN\" or undefined cells, so we must handle the missing data before we begin creating machine learning models.\n",
    "### There are multiple ways to fix missing data:\n",
    "1. Remove the columns with missing data (not recommended, dangerous)\n",
    "2. Set the cell's data to the mean of the columns <b>(recommended)<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn's Imputer class, a class that handles missing data\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an SimpleImputer that replaces NaN cells with its column's mean\n",
    "# SHIFT+TAB on class/function to see parameters should be passed in SimpleImputer()\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit\n",
    "The fit part is used to analyse the data on which we apply the object (getting the mean, the min, the max, the standard deviation, outliers, etc.) in order to understand how the data is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the columns for the imputer\n",
    "imputer = imputer.fit(x[:, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform\n",
    "Then once the object understands how the data is structured thanks to the fit method, the transform part is used to apply some transformation (like feature scaling for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the age (col 1) and salary (col 2) columns\n",
    "x[:, 1:3] = imputer.transform(x[:, 1:3])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = pd.DataFrame(x, columns = [\"Country\",\"Age\",\"Salary\"])\n",
    "y_df = pd.DataFrame(y,columns = [\"Purchased\"])\n",
    "\n",
    "# concatenate both dataframes for new data set\n",
    "customers_df = pd.concat([x_df,y_df], axis = 1)\n",
    "\n",
    "# create new .csv file\n",
    "customers_df.to_csv(\"data/new_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>France</td>\n",
       "      <td>44</td>\n",
       "      <td>72000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>27</td>\n",
       "      <td>48000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Germany</td>\n",
       "      <td>30</td>\n",
       "      <td>54000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Spain</td>\n",
       "      <td>38</td>\n",
       "      <td>61000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Germany</td>\n",
       "      <td>40</td>\n",
       "      <td>63777.8</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>France</td>\n",
       "      <td>35</td>\n",
       "      <td>58000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Spain</td>\n",
       "      <td>38.7778</td>\n",
       "      <td>52000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>France</td>\n",
       "      <td>48</td>\n",
       "      <td>79000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Germany</td>\n",
       "      <td>50</td>\n",
       "      <td>83000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>France</td>\n",
       "      <td>37</td>\n",
       "      <td>67000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country      Age   Salary Purchased\n",
       "0   France       44    72000        No\n",
       "1    Spain       27    48000       Yes\n",
       "2  Germany       30    54000        No\n",
       "3    Spain       38    61000        No\n",
       "4  Germany       40  63777.8       Yes\n",
       "5   France       35    58000       Yes\n",
       "6    Spain  38.7778    52000        No\n",
       "7   France       48    79000       Yes\n",
       "8  Germany       50    83000        No\n",
       "9   France       37    67000       Yes"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Data\n",
    "The \"Country\" and \"Purchased\" columns are categorial variables.\n",
    "\n",
    "* The Country column contains 3 categories: France, Spain, Germany\n",
    "* The Purchased column contains 2 categories: Yes & No\n",
    "\n",
    "They are considered \"categorical\" because they simply contain categories.\n",
    "\n",
    "### The Problem with Categorical Variables\n",
    "In Machine Learning, having categorial variables may scew the model because the values could be non-numeric or non-processable.\n",
    "\n",
    "A solution is to encode categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 44.0, 72000.0],\n",
       "       [2, 27.0, 48000.0],\n",
       "       [1, 30.0, 54000.0],\n",
       "       [2, 38.0, 61000.0],\n",
       "       [1, 40.0, 63777.77777777778],\n",
       "       [0, 35.0, 58000.0],\n",
       "       [2, 38.77777777777778, 52000.0],\n",
       "       [0, 48.0, 79000.0],\n",
       "       [1, 50.0, 83000.0],\n",
       "       [0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a labelencoder\n",
    "labelencoder_x = LabelEncoder()\n",
    "\n",
    "# set each country to its encoded value in the Country column\n",
    "x[:, 0] = labelencoder_x.fit_transform(x[:, 0])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem with The \"Country\" Column's Encoding\n",
    "If we implemented a machine learning model using the country encodings of 0, 1, or 2, then it would think the country with an encoding of 2 has a greater value than the countries of an encoding of 1 and 0.\n",
    "\n",
    "This is not the case since the values are categorical.\n",
    "\n",
    "### A Solution to The Column's Encoding Problem\n",
    "We can create Dummy variables/columns for the three countries.\n",
    "\n",
    "* Instead of having 1 column of the 3 countries, create 3 columns\n",
    "    * These 3 columns would indicate whether or not the country was present per cell based on the Country column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mckka\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, 44.0, 72000.0],\n",
       "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
       "       [0.0, 1.0, 0.0, 30.0, 54000.0],\n",
       "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
       "       [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
       "       [1.0, 0.0, 0.0, 35.0, 58000.0],\n",
       "       [0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
       "       [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
       "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
       "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "a transformer to encode the Country column as dummy columns\n",
    "- remainder=passthrough guarantees that after fit_transforming the\n",
    "preprocess object, x contains all other variables (Age, Salary)\n",
    "and not just the transformed one (Country)\n",
    "\"\"\"\n",
    "dummy_transformer = make_column_transformer((OneHotEncoder(), [0]),\n",
    "                                            remainder=\"passthrough\")\n",
    "\"\"\"\n",
    "replace the Country column with 3 columns with values of 0 or 1\n",
    "- 0 indicates that country was not present in the cell\n",
    "- 1 indicates that country was present in the cell\n",
    "\"\"\"\n",
    "x = dummy_transformer.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "simply encode the Purchased column because the column's values\n",
    "are only \"Yes\" or \"No\", so it doesn't need dummy columns\n",
    "\"\"\"\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into Training and Testing Data Sets\n",
    "Let's split the customers data set into training and testing sets.\n",
    "\n",
    "* <b>Training data sets </b> are used by the machine learning model to learn.\n",
    "* <b>Testing data sets </b> are used by the machine learning model to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create x, y training and testing sets\n",
    "- x = independent variable\n",
    "- y = dependent variable\n",
    "- test_size = what percentage of data is for testing, 20% for our case\n",
    "- random_state = which state (seed) to split the data sets\n",
    "\"\"\"\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The x-training set:\n",
      "[[0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 37.0 67000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [1.0 0.0 0.0 44.0 72000.0]\n",
      " [1.0 0.0 0.0 35.0 58000.0]]\n",
      "\n",
      "The x-testing set:\n",
      "[[0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]]\n",
      "\n",
      "The y-training set:\n",
      "[1 1 1 0 1 0 0 1]\n",
      "\n",
      "The y-testing set:\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# print the training and testing sets for x & y\n",
    "print(\"The x-training set:\")\n",
    "print(x_train)\n",
    "\n",
    "print(\"\\nThe x-testing set:\")\n",
    "print(x_test)\n",
    "\n",
    "print(\"\\nThe y-training set:\")\n",
    "print(y_train)\n",
    "\n",
    "print(\"\\nThe y-testing set:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns are not within the same scale, which causes issues when comparing values in the machine learning models.\n",
    "\n",
    "For example, the \"Age\" column has values from 27 to 50. If we compare that to the \"Salary\" column, which has values from 52,000 to 83,000, then obviously the \"Salary\" column would dominate in value.\n",
    "\n",
    "### Why would these errors occur?\n",
    "Most ML models follow the Euclidian distance (distance formula).\n",
    "\n",
    "If a column has much wider range of values than another column, then the wider range of values would dominate the smaller range of values.\n",
    "\n",
    "### Solving the Scaling Problem\n",
    "We can solve this number scaling problem through 2 feature scaling methods.\n",
    "\n",
    "Either method you choose, the variables become in the same range and in the same scale, thus no variables dominate another variable when comparing them.\n",
    "\n",
    "##### Standarization\n",
    "stand_value(x) = [x - mean(x)] / standard_deviation(x)\n",
    "\n",
    "Standardization rescales data to have a mean (μ) of 0 and standard deviation (σ) of 1 (unit variance)\n",
    "\n",
    "##### Normalization\n",
    "norm_value(x) = [x - min(x)] / [max(x) - min(x)]\n",
    "\n",
    "Normalization rescales the values into a range of [0,1]\n",
    "* This might be useful in some cases where all parameters need to have the same positive scale\n",
    "\n",
    "However, the outliers from the data set are lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### When Scaling This 2D Array Using Standarized Scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [[1, 500, 1250],\n",
    "       [0, 750, 1000],\n",
    "       [0.5, 1000, 750]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It Becomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [[ 1.22474487, -1.22474487,  1.22474487],\n",
    "       [-1.22474487,  0.        ,  0.        ],\n",
    "       [ 0.        ,  1.22474487, -1.22474487]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the individual columns are all now on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Standarization Scaler for the x sets\n",
    "sc_x = StandardScaler()\n",
    "\n",
    "# standarize the x-training set\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "\n",
    "\"\"\"\n",
    "standarize the x-testing set using the same scaler.\n",
    "\n",
    "we use the standarized scaling from the fitted training\n",
    "data set on the testing data set because it compares\n",
    "the testing data set values to the same mean, standard\n",
    "deviation, min, and max from the training data set.\n",
    "\n",
    "therefore, the feature scaling on the testing data set\n",
    "is the same as the feature scaling on the training data\n",
    "set because they were both fitted using the same scaler.\n",
    "\"\"\"\n",
    "x_test = sc_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        ,  2.64575131, -0.77459667,  0.26306757,  0.12381479],\n",
       "       [ 1.        , -0.37796447, -0.77459667, -0.25350148,  0.46175632],\n",
       "       [-1.        , -0.37796447,  1.29099445, -1.97539832, -1.53093341],\n",
       "       [-1.        , -0.37796447,  1.29099445,  0.05261351, -1.11141978],\n",
       "       [ 1.        , -0.37796447, -0.77459667,  1.64058505,  1.7202972 ],\n",
       "       [-1.        , -0.37796447,  1.29099445, -0.0813118 , -0.16751412],\n",
       "       [ 1.        , -0.37796447, -0.77459667,  0.95182631,  0.98614835],\n",
       "       [ 1.        , -0.37796447, -0.77459667, -0.59788085, -0.48214934]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        ,  2.64575131, -0.77459667, -1.45882927, -0.90166297],\n",
       "       [-1.        ,  2.64575131, -0.77459667,  1.98496442,  2.13981082]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
